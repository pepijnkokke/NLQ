\documentclass[a4paper]{article}

\input{preamble}

\begin{document}

% ``We are constructing a \emph{grammar logic}. Therefore, we only
% want features in our logic for which we can demonstrate a motivating
% example from natural language.''

% - implicit semantic calculus;
% - explicit semantic calculus;
% - syntactic calculus;
% - display calculus;
% - compositionality principle;
% - problems with compositionality;
% - quantifier raising and scope ambiguity;
% - continuation monad & delimited continuations;
% - extension: lexical ambiguity;
% - extension: quantifier raising
%   * treatment of some & every;
%   * treatment of same & different;
%   * treatment of plurals;
% - extension: scope islands;

\include{introduction}
\include{display-calculus}
\include{lexical-ambiguity}
\include{natural-language-effects-and-movement}

\section{Movement and Quantifier Raising}%
\label{sec:movement-and-quantifier-raising}

In the previous section, we discussed the framework of monadic
semantics and extensible effects. This framework is extremely
powerful. As mentioned, it provides a flexible and powerful framework
for a large spectrum of complex natural language phenomena such as
context, intensionality, expressives and quantification.

In this section, we will study quantification in more detail.
Quantification is the problem of analysing scope-taking expressions in
natural language. For instance, the canonical interpretation for a
sentence such as ``Everyone laughs'' is:
\[
  \forall{x}.\PERSON(x)\supset\LAUGH(x)
\]
The easiest way to obtain these semantics in NL is to assign
`everyone' the type $\S\impl\IV$---i.e.\ make it a higher-order
function that takes verb phrase in need of a subject, and scopes over
it. With this type, we can assign `everyone' the interpretation
$\lambda{k}.\forall{x}.\PERSON(x)\supset(k\;x)$, and derive the above
semantics as expected.

However, we run into problems as soon as we try to apply the above
solution to quantifiers in object position, such as in ``John saw
everyone''. Because $\S\impl(\NP\impr\S)$---unfolding the IV used
above---scopes over a verb phrase in need of a subject, we cannot use
it here. In the \emph{associative} Lambek calculus, we can use the
deceptively similar looking type $(\S\impl\NP)\impr\S$---a similarity
which extended the popularity of the associative Lambek calculus way
past its due date. Meanwhile, in NL, we have to devise a type which
actually reflects the sentence structure, such as $\TV\impr\IV$. Using
this type, we can assign `everyone' a second interpretation,
$\lambda{k}.\lambda{x}.\forall{y}.\PERSON(y)\supset(k\;y\;x)$, which
gives us the following interpretation for our example:
\[
  \forall{y}.\PERSON(y)\supset\PAST(\SEE(\JOHN,y))
\]
The need for multiple definitions for `everyone' aside, there are more
problems with this approach. For instance, in natural language we
observe a phenomenon known as `scope ambiguity', which is to say that
sentences containing multiple quantifiers are ambiguous. For instance,
``Everyone loves someone'' has two interpretations:
\begin{alignat*}{3}
  &\forall x.\PERSON(x) \,&\supset \,&\exists y.\PERSON(y) \,&\wedge  \,&\LIKE(x,y)\\
  &\exists y.\PERSON(y) \,&\wedge  \,&\forall x.\PERSON(x) \,&\supset \,&\LIKE(x,y)
\end{alignat*}
However, with our current definitions for `everyone'---and a similar
definition for `someone'---we can only derive the first of these
interpretations. Now, we could imagine giving a third definition for
`everyone' and `someone', with the type $(\S\impl\IV)\impr(\TV\impr\IV)$,
which would allow us to define object quantifiers taking scope over
subject quantifiers. However, there are many other cases---think of
ditransitive verbs, or verb phrases modified by some number of
adverbs. Clearly, this way lies madness.

In the following section, we will discuss semantic approaches to the
problem of quantification---approaches trying to solve the problem
within the framework of monadic or effectful semantics---and why these
solutions are generally inadequate.
Next, we will discuss the approach to quantification taken by
\citet{barker2007,barker2015}. We will then reformulate this approach
as an extension of display NL that maintains the properties we are
interested in---i.e. admissibility of cut, and a decidable and complete
proof search procedure. In \autoref{sec:scope-islands} we will discuss
an extension which can be used to treat a phenomenon known as `scope
islands'. And finally, we will discuss some other forms of
movement---infixation and extraction---and show how they can be used
to analyse sentences with gaps.

\subsection{Quantification and Continuation-Passing Style}
\citet{barker2002,barker2004} advocates the use of continuations in
natural language semantics. He does this with several case studies,
one of which is quantification. The gist of this is as follows:

As mentioned before, the utterance ``John saw everyone,'' the
function-argument structure `(sees everyone) john', but we associate
it with the interpretation $\forall
x.\PERSON(x)\supset\SEE(\JOHN,x)$. This means that the expression
`everyone,' which is deeply nested in the parse tree, must somehow
scope over the entire expression.
\citeauthor{barker2004} proposes to solve this problem by applying a
(nonstandard) continuation-passing style (CPS) translation to the
lexicon. He lifts expressions of type $A$ into the type $(A\ra R)\ra
R$ for some answer type $R$:
\begin{alignat*}{3}
  &\text{john}     &&= \lambda k. k\;\JOHN\\
  &\text{sees}     &&= \lambda k. k\;\SEE
  \intertext{%
    He then uses this freedom to define `everyone' as a lifted expression
    of type `\e', with $R$ instantiated to `\t':
  }
  &\text{everyone} &&= \lambda k. \forall x.\PERSON(x)\supset k\;x
\end{alignat*}
In addition, he defines a translation on terms, replacing function
application with a method of combining CPS-translated terms:\footnote{%
  It should be noted that \citeauthor{barker2004}'s initial solution
  uses some directional information to ensure that scope-takers are
  always processed in a left-to-right order, instead of always
  processing the argument first, as it is presented here.
  This distinction, however, becomes irrelevant once he introduces the
  ambiguous translation, and therefore I have chosen not to include it.
}
\[
  \overline{M\;N}= \lambda k. \overline{N}\;(\lambda
  n.\overline{M}\;(\lambda m.k\;(m\;n)))
\]
As CPS-translations and monadic translations are closely related
\citep{filinski1994}, it is rather easy to implement approaches using
a CPS translation as a monad or an effect---in fact, \citet{shan2002}
already provides such an implementation.

However, the analysis of quantification as a side-effect has several
major issues. The first of these is already mentioned by
\citet{barker2004}: scope ambiguity. The sentence ``Everyone likes
someone'', is ambiguous:
\begin{alignat*}{3}
  &\forall x.\PERSON(x) \,&\supset \,&\exists y.\PERSON(y) \,&\wedge  \,&\LIKE(x,y)\\
  &\exists y.\PERSON(y) \,&\wedge  \,&\forall x.\PERSON(x) \,&\supset \,&\LIKE(x,y)
\end{alignat*}
The solution provided by \citet{barker2002,barker2004} will only
derive the first of these meanings. Barker solves this problem by
adding another possible translation for function application, thereby
making the CPS-translation ambiguous:
\begin{alignat*}{3}
  &\overline{M\;N} &&= \lambda k. \overline{N}\;(\lambda
  n.\overline{M}\;(\lambda m.k\;(m\;n)))\\
  &\overline{M\;N} &&= \lambda k. \overline{M}\;(\lambda
  m.\overline{N}\;(\lambda n.k\;(m\;n)))
\end{alignat*}
There are several problems with this solution. First of all, this
results in a huge amount of spurious ambiguity. A sentence with $n$
words has $n-1$ function applications, and will therefore have
$2^{(n-1)}$ ``different'' interpretations. However, the ambiguity is
only relevant for scope-takers. In the motivating example, ``likes''
is not a scope taker. Nevertheless, there are two possible
translations for ``likes someone'', resulting in \emph{four}
interpretations for the sentence where we only want two.

Secondly, using an ambiguous translation clearly makes our
CPS-translation incompatible with our monadic translation, unless we
are willing to ambiguously translate all our effects. But doing so is
risky, as a right-to-left interpretation may not be desirable for
effects other than quantification. For instance, a right-to-left
interpretation of the state monad for anaphora resolution will allow
sentences such as ``He$_i$ gave a book to John$_i$.''

\vspace*{1\baselineskip}

In more recent work, \citet{moortgat2012} integrate CPS-semantics into
the syntactic calculus. The result is the Lambek-Grishin (LG)
calculus, a classical variant of NL, with semantics inspired on
\citeauthor{parigot1992}'s $\lambda\mu$-calculus
(\citeyear{parigot1992}). LG is a beautifully symmetric calculus, and
display NL, as used in this thesis is, is directly based from it. The
integrated CPS-semantics give some interesting opportunities, for
instance the ability to give quantifiers such as `everyone' the type
$(NP\oslash N)\otimes N$---a pair of a determiner and a noun---and
give them the desired scope-taking semantics.

\vspace*{1\baselineskip}

\citeauthor{barker2004}'s CPS-translation and
\citeauthor{moortgat2012}'s CPS-semantics both suffer from two related
problems:
\begin{enumerate}
\item Both require a \emph{static} choice of answer type. This
  means that the answer type cannot change throughout the
  program. However, there are examples which demonstrate the need for
  allowing dynamic answer types.
\item Both cannot encode \emph{delimiters} past which a nested
  expression cannot take scope. However, in natural language we find
  evidence for scope islands\footnote{%
    We will discuss scope islands in
    \autoref{sec:movement-and-quantifier-raising}.
  }, from which quantifiers cannot escape.
\end{enumerate}
These are the hallmark of \emph{delimited} or \emph{composable}
continuations \citep{danvy1990}. However, while delimited
continuations seem extremely promising, they are still not entirely
without problems. They still suffer from the problem of ambiguity, as
described above for CPS- and monadic translations. Additionally, they
do not form a monad. Instead, they form something known as an indexed
monad, which has two additional type-level parameters, meaning $\eta$
and $\star$ get the following types:
\[
  \eta : A\ra\mathbb{M}\;i\;i\;A
  \qquad
  \star: (A\ra\mathbb{M}\;j\;k\;B)\ra\mathbb{M}\;i\;j\;A\ra\mathbb{M}\;i\;k\;B
\]
This makes sense: since we now allow the answer type of the
continuation to change, we need to add indices to keep track of the
input and output answer type. However, the downside of this is that
since we need these additional parameters, we cannot simply
CPS-translate to delimited continuations---if we use a delimited
continuation indexed monad in our semantics, this will have to be
reflected in our syntactic calculus.

While such a solution using delimited continuations may still be
interesting to examine, we will choose to keep our solution entirely
syntactic. In the next section we will present quantifier movement and
scope islands in the syntactic calculus, based on work by
\citet{moortgat1996}, \citet{barker2007} and \citet{barker2015}.

\subsection{NL$_\lambda$, NL$_{\text{CL}}$ and NL$_{\text{IBC}}$}
In their \citeyear{barker2015} book, \citeauthor{barker2015} describe
an extension of NL which they call NL$_\lambda$. The main insight in
the formulation of this calculus was this: in type-logical grammar,
the antecedent encodes a constituency tree, therefore we can simply
encode quantifier raising in our logic.
\begin{center}
  \vspace*{0.5\baselineskip}
  \begin{minipage}{0.3\linewidth}
    \begin{tikzpicture}
      \Tree [ john [ likes everyone ] ]
    \end{tikzpicture}
  \end{minipage}%
  \begin{minipage}{0.02\linewidth}
    $\equiv$
  \end{minipage}%
  \begin{minipage}{0.4\linewidth}
    \begin{tikzpicture}
      \Tree [ everyone [ $\lambda x.$ [ john [ likes x ] ] ] ]
    \end{tikzpicture}
  \end{minipage}
\end{center}
To achieve this, they add a new mode to NL---that is to say, a copy of
the rules for $\{\impr,\prod,\impl\}$ applying to three new connectives
$\{\himpr,\hprod,\himpl\}$---and the following (somewhat controversial)
equivalence on structures:
\[
  \Sigma[\Delta]\equiv\Delta\circ\lambda x.\Sigma[x]
\]
This equivalence is intuitive, and works as expected. For instance,
using display NL extended with this equivalence, we can easily give a
derivation for ``John likes everyone,'' using the type
$\S\himpl(\NP\himpr\S)$ for quantifiers:
\begin{pfblock}
  \AXC{$\vdots$}\noLine
  \UIC{$\struct{\NP}\prod\struct{(\NP\impr\S)\impl\NP}\prod\struct{\NP}
    \fCenter\struct{\S}$}
  \RightLabel{$\lambda$}
  \UIC{$\struct{\NP}\hprod\lambda{x}.
    (\struct{\NP}\prod\struct{(\NP\impr\S)\impl\NP}\prod x)\fCenter\struct{\S}$}
  \RightLabel{Res$\hprod\himpr$}
  \UIC{$\lambda{x}.(\struct{\NP}\prod\struct{(\NP\impr\S)\impl\NP}\prod{x})
    \fCenter\struct{\NP}\himpr\struct{\S}$}
  \RightLabel{R$\himpr$}
  \UIC{$\lambda{x}.(\struct{\NP}\prod\struct{(\NP\impr\S)\impl\NP}\prod{x})
    \fCenter\struct{\NP\himpr\S}$}
  \AXC{}\RightLabel{Ax}\UIC{$\struct{S}\fCenter\struct{S}$}
  \BIC{$\struct{\S\himpl(\NP\himpr\S)}\fCenter\struct{\S}\himpl\lambda{x}.
    (\struct{\NP}\prod\struct{(\NP\impr\S)\impl\NP}\prod x)$}
  \RightLabel{Res$\himpl\:\hprod$}
  \UIC{$\struct{\S\himpl(\NP\himpr\S)}\hprod\lambda{x}.
    (\struct{\NP}\prod\struct{(\NP\impr\S)\impl\NP}\prod x)\fCenter\struct{\S}$}
  \RightLabel{$\lambda$}
  \UIC{$\struct{\NP}\prod\struct{(\NP\impr\S)\impl\NP}\prod\struct{\S\himpl
      (\NP\himpr\S)}\fCenter\struct{\S}$}
\end{pfblock}
However, the use of a binding construct in the syntax for structures
makes this equivalence quite difficult to formalise.
In addition, if we were to take the equivalence at face value, we
would end up with a logic in which we could do all kinds of unpleasant
things. For instance, since contexts are defined as structures with a
hole, we could raise quantifiers past one another, indefinitely:
\begin{pfblock}
  \AXC{$\vdots$}\noLine
  \UIC{$\struct{{\S\impl(\NP\impr\S)}}\hprod\lambda{z}.(\struct{{\S\impl(\NP\impr\S)}}\hprod\lambda{y}.({z}\hprod\lambda{x}.({y}\prod\struct{(\NP\impr\S)\impl\NP}\prod{x})))\fCenter\struct{\S}$}
  \RightLabel{$\lambda$}
  \UIC{$\struct{{\S\impl(\NP\impr\S)}}\hprod\lambda{y}.(\struct{{\S\impl(\NP\impr\S)}}\hprod\lambda{x}.({y}\prod\struct{(\NP\impr\S)\impl\NP}\prod{x}))\fCenter\struct{\S}$}
  \RightLabel{$\lambda$}
  \UIC{$\struct{{\S\impl(\NP\impr\S)}}\hprod\lambda{x}.(\struct{{\S\impl(\NP\impr\S)}}\prod\struct{(\NP\impr\S)\impl\NP}\prod{x})\fCenter\struct{\S}$}
  \RightLabel{$\lambda$}
  \UIC{$\struct{{\S\impl(\NP\impr\S)}}\prod\struct{(\NP\impr\S)\impl\NP}\prod\struct{{\S\impl(\NP\impr\S)}}\fCenter\struct{\S}$}
\end{pfblock}
Or, as \citet{barker2015} note, we could lift variables out of the
scope of their binder:
\begin{pfblock}
  \AXC{$\vdots$}\noLine
  \UIC{${x}\hprod\lambda{y}.(\struct{{\S\impl(\NP\impr\S)}}\hprod\lambda{x}.(\struct{{\S\impl(\NP\impr\S)}}\prod\struct{(\NP\impr\S)\impl\NP}\prod{y}))\fCenter\struct{\S}$}
  \RightLabel{$\lambda$}
  \UIC{$\struct{{\S\impl(\NP\impr\S)}}\hprod\lambda{x}.(\struct{{\S\impl(\NP\impr\S)}}\prod\struct{(\NP\impr\S)\impl\NP}\prod{x})\fCenter\struct{\S}$}
  \RightLabel{$\lambda$}
  \UIC{$\struct{{\S\impl(\NP\impr\S)}}\prod\struct{(\NP\impr\S)\impl\NP}\prod\struct{{\S\impl(\NP\impr\S)}}\fCenter\struct{\S}$}
\end{pfblock}
Needless to say, any logic extended with this equivalence loses a
number of pleasant properties, one of which is decidable proof
search. However, in chapter 17 of their book, \citeauthor{barker2015}
do a great job of capturing the essence of the $\lambda$-rule in a
logical manner; while their system is not yet decidable, it is very
nearly so. They extend NL by a second modality
$\{\himpr,\hprod,\himpl\}$, add three primitive structural constants
$\{\I,\B,\C\}$, and add the following structural rules:
\begin{center}
  \begin{pfbox}
    \AXC{$X\fCenter Y$}
    \doubleLine\RightLabel{\I}
    \UIC{$X\hprod\I\fCenter Y$}
  \end{pfbox}
  \begin{pfbox}
    \AXC{$X\prod(Y\hprod Z)\fCenter W$}
    \doubleLine\RightLabel{\B}
    \UIC{$Y\hprod((\B\prod X)\prod Z)\fCenter W$}
  \end{pfbox}
  \begin{pfbox}
    \AXC{$(X\prod Y)\hprod Z\fCenter W$}
    \doubleLine\RightLabel{\C}
    \UIC{$X\hprod((\C\prod Y)\prod Z)\fCenter W$}
  \end{pfbox}
\end{center}
They call the result NL$_{\text{CL}}$ (and, occasionally,
NL$_{\text{IBC}}$). In this calculus, quantifier raising can be done
in much the same way as in NL$_\lambda$---though the new version is
ever so slightly more verbose:\footnote{%
  Inverted applications of the \I, \B\ and \C\ rules are marked with a prime.
}
\input{fig-example-quantifier-raising}
One of the advantages of this formalisation is that it gets rid of the
awkward binding construct in the syntax of structures. In addition, it
makes it clear that quantifiers can only move past \emph{solid}
products. However, it is not entirely free of problems. One of the
more glaring problems is that using this encoding, any expression can
be the subject of quantifier raising. For instance, in ``John likes
Mary,'' we could choose to raise the verb:
\begin{pfblock}
  \AXC{$\vdots$}\noLine
  \UIC{$\struct{{(\NP\impr\S)\impl\NP}}\hprod(\B\prod\struct{\NP})
    \prod((\C\prod\I)\prod\struct{\NP})\fCenter\struct{\S}$}\noLine
  \UIC{$\vdots$}\noLine
  \UIC{$\struct{\NP}\prod\struct{{(\NP\impr\S)\impl\NP}}\prod\struct{\NP}\fCenter\struct{\S}$}
\end{pfblock}
Since verbs are usually not considered scope-takers, it is unlikely
that raising the verb would lead to anything other then lowering it
again. However, the fact that we leave it open as an opportunity is
wasted computational effort; while all futile attempts at raising and
lowering will lead to a loop, and therefore spare us the spurious
ambiguity, there are still a great deal of futile attempts to be made.

Another problem is the $\I'$-rule. It allows us to introduce an
arbitrary amount of \I's, which causes a \emph{growing} loop in our
proof search procedure:
\begin{pfblock}
  \AXC{$\vdots$}\noLine
  \UIC{$((\struct{\NP}\prod\struct{\NP\impr\S})\hprod\I)\hprod\I\fCenter\struct{\S}$}
  \RightLabel{$\I'$}
  \UIC{$(\struct{\NP}\prod\struct{\NP\impr\S})\hprod\I\fCenter\struct{\S}$}
  \RightLabel{$\I'$}
  \UIC{$\struct{\NP}\prod\struct{\NP\impr\S}\fCenter\struct{\S}$}
\end{pfblock}
I propose to handle both of these issues with one simple addition. The
idea is to add a new unary connective, $\q[A]$, which represents a
license to perform quantifier raising. Since we want to replace the
problematic $\I'$-rule, we will choose the structural version of our
quantifying license to be a \emph{hollow} product with a right-hand
unit. On the other side, since we do not want logical products, we
will keep $\q[A]$ it as an atomic logical connective. This gives us
the following logical left rule:
\begin{pfblock}
  \AXC{$\struct{A}\hprod\I\fCenter Δ$}
  \RightLabel{L\I}
  \UIC{$\struct{\q[A]}\fCenter Δ$}
\end{pfblock}
The appropriate right rule is easily derived from the conventional
display calculus rules for products and units---though I do not imagine
we will generally want to see quantifying licenses in our output type:
\begin{pfblock}
  \AXC{$Γ\fCenter\struct{B}$}
  \RightLabel{R\I}
  \UIC{$Γ\hprod\I\fCenter\struct{\q[B]}$}
\end{pfblock}
And indeed, the pair obeys all constraints imposed by display
calculus, including a valid proof for \textbf{C8}:
\begin{pfblock}
  \AXC{$Γ\fCenter\struct{A}$}
  \AXC{$\struct{A}\hprod\I\fCenter Δ$}
  \RightLabel{Res$\hprod\himpl$}
  \UIC{$\struct{A}\fCenter Δ\himpl\I$}
  \RightLabel{Cut}
  \BIC{$Γ\fCenter Δ\himpl\I$}
  \RightLabel{Res$\himpl\hprod$}
  \UIC{$Γ\hprod\I\fCenter Δ$}
\end{pfblock}
Note that we keep the $\I$-rule, though we rename it $\I^-$ to
emphasise that it can now only \emph{remove} $\I$s. The full
extension, including semantics, and focused rules, can be found in
\autoref{fig:extension-quantifier-raising}. The semantics are rather
trivial: we simply translate all constants as units, and translate
$\q[A]$ as $A$, inserting and removing the right unit as needed.

\input{fig-extension-quantifier-raising}

The extension presented so far for quantifier raising is pretty good:
because we have removed all growing loops in structural rules, it now
has a decidable and complete procedure for proof search, and it neatly
captures quantifier movement---i.e. moving upwards, taking scope,
binding a variable, and moving that variable back down. However, it
still has one problem: spurious ambiguity. Imagine a sentence with two
quantifiers $P$ and $Q$, respectively \emph{one} and \emph{two} places
removed from the top of the syntax tree. The ambiguity that we want is
``do we raise $P$ first, or do we raise $Q$ first?'' However, in
addition to these possibilities, we now also have to possibility to
raise $Q$ one step, then raise $P$, and then raise $Q$ a second
step---semantically, this is equivalent to raising $P$, then
$Q$. NL$_\lambda$---if you only allow quantifier raising past solid
products---does not have this problem.

\citet[][chapter 17.6]{barker2015} examine the restrictions that need
to be put on the $\lambda$-rule in order to be able to translate
NL$_\lambda$ to NL$_{\text{CL}}$. In order to keep our structural
rules simple, and our calculus free of structural lambdas, I opt to go
the other way around, and see how close we can get to defining the
$\lambda$-rule in our calculus in \autoref{fig:extension-quantifier-raising}.
For this, we will need the following definitions:
\begin{center}
  $\text{Context}\;Σ\coloneqq\Box\vsep Σ\prodl Γ\vsep Γ\prodr Σ$\\
  \begin{minipage}{0.45\linewidth}
    \begin{alignat*}{2}
      &\Box       \;&&[Γ']\mapsto Γ'\\
      &(Σ\prodl Γ)\;&&[Γ']\mapsto (Σ[Γ']\prod Γ)\\
      &(Γ\prodr Σ)\;&&[Γ']\mapsto (Γ\prod Σ[Γ'])
    \end{alignat*}
  \end{minipage}
  \begin{minipage}{0.45\linewidth}
    \begin{alignat*}{2}
      &\trace(\Box)     \;&&\mapsto \mathbf{I}\\
      &\trace(Σ\prodl Γ)\;&&\mapsto ((\mathbf{C}\prod \trace(Σ))\prod Γ)\\
      &\trace(Γ\prodr Σ)\;&&\mapsto ((\mathbf{B}\prod Γ)\prod
      \trace(Σ))
    \end{alignat*}
  \end{minipage}
\end{center}
First we have contexts, which encode structures with a single hole,
where the nodes leading up to the hole are all solid
products---exactly the type of structure that quantifiers can move up
through. The syntax is a little abusive, as we use the same symbol for
products, products with a hole in their left argument, and products
with a hole in their right argument. However, as we require that
contexts have only a single hole, it is always unambiguous. Note that
products are right-associative.
Secondly, we have the plugging function `$\plug$', which inserts some
structure into the single hole in a context.
Lastly, the `trace' function computes, from a context, the trace of
$\B$s and $\C$s that would be left after something quantifies out of
that context.

Given these definitions, we can show that the following rule for
quantifier movement is admissible, by induction on the structure of
the context:
\begin{pfblock}
  \AXC{$\struct{A}\hprod\trace(Σ)\fCenter Δ$}
  \doubleLine\RightLabel{$\uparrow\downarrow$}
  \UIC{$Σ[\struct{\q[A]}]\fCenter Δ$}
\end{pfblock}
This new rule is very close to \citeauthor{barker2015}'s equivalence,
with as its only difference that the quantifying license is now built
into it:
\[
  \Sigma[\Delta]\equiv\Delta\circ\lambda x.\Sigma[x]
  \qquad
  Σ[\struct{\q[A]}]\equiv\struct{A}\hprod\trace(Σ)
\]
In fact, if you read products as function applications, and the
constants $\{\I,\B,\C\}$ as the combinators, as \citet{barker2015}
intended, then the right-hand side expressions are more-or-less
equivalent.\footnote{%
  As an aside: what we set out to encode were contexts with holes that
  are unique---plugging should never duplicate or forget
  information. So the $\lambda$-terms in NL$_\lambda$ were implicitly
  linear. The combinators $\I$, $\B$ and $\C$ correspond precisely to
  the linear lambda calculus. However, the combinator language is far
  easier to encode than linear binding constructs.
}
Proof search with this derived rule is still complete; it merely
enforces that the entire quantifier raising or lowering is done in one
go.\todo{No proof.}

In their discussion of decidability, \citet{barker2015} derive the
`expansion' and `reduction' rules which more-or-less correspond to
the two directions of the equivalence, or the two directions of our
$\uparrow\downarrow$-rule. They then combine these rules with
L$\himpl$ and R$\himpr$, respectively, yielding the
$\himpl\,\text{L}_\lambda$ and $\himpr\text{R}_\lambda$ rules. The
advantage of these combined rules is that they obey the sub-formula
property, and are therefore suited to naive backward-chaining proof
search. We can do a similar thing using our $\uparrow\downarrow$-rule:
\begin{center}
  \begin{pfbox}
    \AXC{$\trace(Σ)\fCenter\struct{A\himpr B}$} \AXC{$\struct{C}\fCenter Δ$}
    \RightLabel{\qup}
    \BIC{$Σ[\struct{\q[C\himpl(A\himpr B)]}]\fCenter Δ$}
  \end{pfbox}
  \begin{pfbox}
    \AXC{$Σ[\struct{A}]\fCenter\struct{B}$}
    \RightLabel{\qdown}
    \UIC{$\trace(Σ)\fCenter\struct{A\himpr B}$}
  \end{pfbox}
\end{center}
While proof search with these rules is decidable, it is no longer
complete. However, it \emph{is} complete for the fragment of display
NL where all types involving a quantifying license are of the form
$\q[C\himpl(A\himpr B)]$, which is what we can reasonably expect from
natural language.
In addition, proof search using these rules is no longer plagued by
the spurious ambiguity that resulted from the $\B$ and $\C$
rules---and, to boot, we can write proofs involving quantifier
movement in a much more succinct manner:
\begin{pfblock}
  \AXC{$\vdots$}\noLine
  \UIC{$\struct{\NP}\prod\textsc{loves}\prod\struct{\NP}\fCenter\struct{\S}$}
  \RightLabel{\qdown}
  \UIC{$\trace(\Box\prod\textsc{loves}\prod\struct{\NP})\fCenter\struct{{\NP\himpr\S}}$}
  \AXC{}\RightLabel{Ax}\UIC{$\struct{\S}\fCenter\struct{\S}$}
  \RightLabel{\qup}
  \BIC{$\textsc{everyone}\prod\textsc{loves}\prod\struct{\NP}\fCenter\struct{\S}$}
  \RightLabel{\qdown}
  \UIC{$\trace(\textsc{everyone}\prod\textsc{loves}\prod\Box)\fCenter\struct{{\NP\himpr\S}}$}
  \AXC{}\RightLabel{Ax}\UIC{$\struct{\S}\fCenter\struct{\S}$}
  \RightLabel{\qup}
  \BIC{$\textsc{everyone}\prod\textsc{loves}\prod\textsc{someone}\fCenter\struct{\S}$}
\end{pfblock}
\vspace*{-1\baselineskip}
\begin{gather*}
  \downmapsto
  \\
  (\text{someone}\;(\lambda y. \text{everyone}\;(\lambda x.\text{likes}\;y\;x)))
  \\
  \downmapsto
  \\
  \exists y.\PERSON(y)\wedge\forall x.\PERSON(x)\supset\LIKE(x,y)
\end{gather*}
Note that though we have the option, we do not have to unfold the
application of `trace' in this particular proof. In future proofs, if
we choose to fold or unfold an application of `trace', we will
explicitly mark this as an application of rewriting by equality
(`$=$').

\input{fig-example-changing-answer-type}

\subsection{Parasitic scope}
Parasitic scope is a beautiful mechanism, put forward by
\citet{barker2007}, which allows expressions to capture a quantifier's
scope. Using this mechanism, a parasitic expression can take scope
\emph{right} underneath another quantifier, and capture the bound
variable. For instance, a parasitic expression $k$ might take scope
under the bounded quantifier `everyone', receiving both its context
and the bound variable $x$ as arguments:
\[
  \forall{x}.\PERSON(x)\supset(k\ldots{x})
\]
The mechanism depends crucially on two properties:\footnote{%
  Though I do not rule out the possibility that the mechanism can
  exists under different circumstances.
}
\begin{enumerate*}[label=(\arabic*)]
\item quantification must be (at least) a two-step process; and
\item the `function' that becomes the argument of the quantifier must
  be represented in the type.
\end{enumerate*}
NL$_\lambda$ (obviously) respects these requirements: we have
$\himpl\text{L}_\lambda$ (or $\qup$) and $\himpr\text{R}_\lambda$ (or
$\qdown$), and the type of the `function' that is quantifier-over is
represented as ${A}\himpr{B}$. Using this, we can write a quantifier
which targets the type of raised quantifiers. For instance,
\[
  \q[(\NP\himpr\S)\himpl(\ldots\himpr(\NP\himpr\S))]
\]
Canonical examples of such quantifiers are expressions such as `same'
and `different', as used in the sentence ``The same waiter served
everyone'', which \citet{barker2007} assigns more-or-less the
following semantics:\footnote{%
  I suppose that selection of the choice function $f$ should be
  bounded by a predicate such as $\exists{z}.\forall{x}.f(x)=z$, as
  would be dictated by the semantics of same.
}
\[
  \text{everyone}\;(\lambda{X}.\exists{f_{(\e\t)\e}}.\forall{x<X}:
  \PAST(\SERVE(x,\iota(f(\WAITER)))))
\]
Which \citeauthor{barker2007} describes as meaning that ``[e]veryone
collectively has the property of being a group such that there is a
unique waiter who served each member of the group''. It is clear that
the intention is to have $x$ range over the same set of variables over
which `everyone' ranges. However, it is not entirely clear to me how
`everyone' should reduce---it is ostensibly not a quantifier, but a
function which takes a continuation and provides it with the set of
all people (e.g.\ $\text{everyone}=\lambda{k}.k\;\PERSON$). All this
seems to be a whole lot of work to push the existential selecting the
choice function over the quantifier introduced by `everyone'.

\citet{kiselyov2015b} provides much clearer semantics for the semantics
of `same' and `different' sentences:
\[
  \exists{z}.\forall{y}.\PAST(\SERVE(\iota(\lambda{x}.\WAITER(x)\wedge{x=z}),y))
\]
The crucial point seems to be that words such as `same' want to take
scope \emph{over} another quantifier, but in the meantime also want
access to the variable bound by that quantifier. In order to derive
these semantics, we use a different type for parasitic quantifiers---a
double quantifier:
\[
  \q[\S\himpl(\quad{\q[(\NP\himpr\S)\himpl(\quad{\ldots}\quad\himpr(\NP\himpr\S))]}\quad\himpr\S)]
\]
Such double quantification has some interesting aspects. First of all,
one might expect huge amounts of quantifier ambiguity. However,
because a double quantifier has to take scope once \emph{normally} and
once \emph{parasitically}, in the case where there is one double and
one normal quantifier, there is not room for ambiguity. The double
quantifier \emph{has} to take scope first, in order to be able to take
scope parasitically while the other quantifier is taking scope.

In \autoref{fig:parasitic-scope}, we give an analysis of the sentence
``A different waiter served everyone'', for which we derive the
following semantics, also assigned by \citeauthor{kiselyov2015b}:
\begin{align*}
  &\exists{f_{\e\e\t}}.(\forall{x}.\forall{y}.\nexists{z}.f\;z\;x\wedge{f\;z\;y})\;\wedge\\
  &\qquad(\forall{y}.\PERSON(y)\supset(\exists{x}.\WAITER(x)\wedge{f\;y\;x\wedge\PAST(\SERVE(y,x))}))
\end{align*}
The first clause, $\forall{x}.\forall{y}.\nexists{z}.f\;z\;x\wedge
{f\;z\;y}$, is entirely contained withing the semantics for
`different'---it enforces that $f$ does not assign the same output $z$
to two different inputs. The full lexicon used in the derivation is
given in \autoref{fig:parasitic-scope-lexicon}
\begin{figure}[hb]
  \centering
  \begin{mdframed}
    \[
      \renewcommand*{\arraystretch}{1}
      \begin{array}{l c l}
        \text{a}
        &:& \tr[{(\q[\S\himpl(\NP\himpr\S)]\impl\N)}]\\
        &=& \lambda n. \lambda k. \exists x. n\;x\wedge k\;x\\

        \text{different}
        &:& \tr[{(\q[\S\himpl(\q[(\NP\himpr\S)\himpl(\A\himpr(\NP\himpr\S))]\himpr\S)])}]\\
        &=& \lambda k. \exists f. (\forall x.\forall y.\nexists z.f\;z\;x\wedge f\;z\;y)\;\wedge\\
        & & k\;(\lambda k'.\lambda x.k'\;(\lambda g.\lambda y.g\;y\wedge f\;x\;y)\;x)\\

        \text{waiter}
        &:& \tr[\N]\\
        &=& \lambda x.\WAITER(x)\\

        \text{served}
        &:& \tr[\TV]\\
        &=& \lambda y.\lambda x.\PAST(\SERVE(x,y))\\

        \text{everyone}
        &:& \tr[{(\q[\S\himpl(\NP\himpr\S)])}]\\
        &=& \lambda k.\forall x.\PERSON(x)\supset k\;x
      \end{array}
    \]
  \end{mdframed}
  \caption{Lexicon used in the derivation in \autoref{fig:parasitic-scope}.}
  \label{fig:parasitic-scope-lexicon}
\end{figure}
%
\input{fig-example-parasitic-scope}
%


\subsection{Scope islands}
\label{sec:scope-islands}

\input{fig-extension-scope-islands}


\begin{pfblock}
  \AXC{$\vdots$}\noLine
  \UIC{$\textsc{everyone}\prod\textsc{left}\fCenter\struct{\S}$}
  \RightLabel{L$\di$}
  \UIC{$\langle\textsc{everyone}\prod\textsc{left}\rangle\fCenter\struct{\di\S}$}
  \AXC{$\vdots$}\noLine
  \UIC{$\struct{\NP\impr\S}\fCenter\textsc{mary}\impr\struct{\S}$}
  \RightLabel{L$\impl$}
  \BIC{$
    \textsc{said}\fCenter
    (\textsc{mary}\impr\struct{\S})\impl
    \langle\textsc{everyone}\prod\textsc{left}\rangle$}
  \RightLabel{DP}
  \UIC{$
    \textsc{mary}\prod\textsc{said}\prod
    \langle\textsc{everyone}\prod\textsc{left}\rangle
    \fCenter\struct{\S}$}
\end{pfblock}
\vspace*{-1\baselineskip}
\begin{gather*}
  \downmapsto
  \\
  \text{say}\;(\text{everyone}\;\text{left})\;\text{mary}
  \\
  \downmapsto
  \\
  \SAY(\MARY,\forall{x}.\PERSON(x)\supset\PAST(\LEAVE(x)))
\end{gather*}


\subsection{Infixation, Extraction and Reasoning with Gaps}


%\input{fig-extension-infixation}
%\input{fig-extension-extraction}

\include{future-work}


\bibliographystyle{apalike}
\bibliography{main}%

\end{document}
